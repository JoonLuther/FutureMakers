{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[In Progress]Simple Autoencoder (Day 21).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zish6p8Prci"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "encoding_dim = 32\n",
        "input_img = keras.Input(shape=(784,))\n",
        "\n",
        "encoded = layers.Dense(encoding_dim, activation='relu',)(input_img)\n",
        "\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "#model maps an input to reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfz9M7iOQM8n"
      },
      "source": [
        "#model maps an input to encoded representation\n",
        "encoder = keras.Model(input_img, encoded)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxUW24zDQbFK"
      },
      "source": [
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S63IPaKWQm7k"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j861g36yQ3Li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb177dac-80c1-4bcf-90be-c2aaf975a250"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckQQliWaRBP3",
        "outputId": "b4546ffe-f742-4468-9c8a-056b44970537"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w4IEcRuRDaO",
        "outputId": "879c2d31-d441-40d5-ee8f-1a25ee225444"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 17s 13ms/step - loss: 0.3861 - val_loss: 0.1931\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1815 - val_loss: 0.1509\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1472 - val_loss: 0.1327\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1308 - val_loss: 0.1209\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1198 - val_loss: 0.1122\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1119 - val_loss: 0.1061\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1061 - val_loss: 0.1018\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1024 - val_loss: 0.0991\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0996 - val_loss: 0.0969\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0976 - val_loss: 0.0955\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0968 - val_loss: 0.0945\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0957 - val_loss: 0.0940\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0953 - val_loss: 0.0935\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0948 - val_loss: 0.0932\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0944 - val_loss: 0.0930\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0942 - val_loss: 0.0928\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0939 - val_loss: 0.0927\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0939 - val_loss: 0.0925\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0934 - val_loss: 0.0924\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0935 - val_loss: 0.0924\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0933 - val_loss: 0.0922\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0933 - val_loss: 0.0921\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0930 - val_loss: 0.0920\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0919\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0926 - val_loss: 0.0917\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0919\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0927 - val_loss: 0.0918\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0928 - val_loss: 0.0917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c79621c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG3jZJ1LREqG"
      },
      "source": [
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YrIjREaSEP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "f8787b1d-bdd9-4d67-b1fc-96d9a7fbc7ab"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20,4))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2, n, i+1)\n",
        "  plt.imshow(x_test[1].reshape(28, 28))\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  ax = plt.subplot(2, n, i+1)\n",
        "  plt.imshow(decoded_imgs[1].reshape(28, 28))\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzzJvjBdsHAI"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "encoding_dim = 32\n",
        "\n",
        "input_img = keras.Input(shape=(784,))\n",
        "encoded = layers.Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxyx4RbWsMbF"
      },
      "source": [
        "#Deep Autoencoder using a stack of layers as an encoder\n",
        "input_img = keras.Input(shape=(784,))\n",
        "encoded = layers.Dense(128, activation='relu')(input_img)\n",
        "encoded = layers.Dense(64, activation='relu')(encoded)\n",
        "encoded = layers.Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = layers.Dense(64, activation='relu')(encoded)\n",
        "decoded = layers.Dense(128, activation='relu')(decoded)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQqRL1flsPqY",
        "outputId": "f207d8ee-d387-409e-9a86-a3e92d454efb"
      },
      "source": [
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 5s 19ms/step - loss: 0.3398 - val_loss: 0.1661\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1564 - val_loss: 0.1378\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1364 - val_loss: 0.1274\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1266 - val_loss: 0.1190\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1189 - val_loss: 0.1136\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1140 - val_loss: 0.1105\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1106 - val_loss: 0.1067\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1077 - val_loss: 0.1042\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1049 - val_loss: 0.1023\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1031 - val_loss: 0.1007\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1015 - val_loss: 0.0993\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.1002 - val_loss: 0.0986\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0991 - val_loss: 0.0984\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0983 - val_loss: 0.0964\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0974 - val_loss: 0.0959\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0965 - val_loss: 0.0958\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0959 - val_loss: 0.0948\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0954 - val_loss: 0.0940\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0949 - val_loss: 0.0935\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0939 - val_loss: 0.0930\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0924 - val_loss: 0.0914\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0920 - val_loss: 0.0914\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0919 - val_loss: 0.0910\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0914 - val_loss: 0.0911\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0910 - val_loss: 0.0900\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0906 - val_loss: 0.0899\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0905 - val_loss: 0.0894\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0902 - val_loss: 0.0896\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0897 - val_loss: 0.0889\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0897 - val_loss: 0.0888\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0893 - val_loss: 0.0885\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0892 - val_loss: 0.0884\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0889 - val_loss: 0.0880\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0888 - val_loss: 0.0876\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0885 - val_loss: 0.0878\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0883 - val_loss: 0.0875\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0879 - val_loss: 0.0873\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0877 - val_loss: 0.0870\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0876 - val_loss: 0.0870\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0875 - val_loss: 0.0871\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0874 - val_loss: 0.0868\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0871 - val_loss: 0.0866\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0872 - val_loss: 0.0865\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0867 - val_loss: 0.0862\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0868 - val_loss: 0.0862\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0868 - val_loss: 0.0861\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0866 - val_loss: 0.0860\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0865 - val_loss: 0.0860\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0864 - val_loss: 0.0857\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0862 - val_loss: 0.0856\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0862 - val_loss: 0.0854\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0862 - val_loss: 0.0854\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0858 - val_loss: 0.0854\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0859 - val_loss: 0.0854\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0856 - val_loss: 0.0855\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0854 - val_loss: 0.0852\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0856 - val_loss: 0.0852\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0857 - val_loss: 0.0851\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0853 - val_loss: 0.0850\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0854 - val_loss: 0.0848\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0853 - val_loss: 0.0849\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0853 - val_loss: 0.0848\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0851 - val_loss: 0.0847\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0851 - val_loss: 0.0846\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0851 - val_loss: 0.0847\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0851 - val_loss: 0.0847\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0851 - val_loss: 0.0843\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0848 - val_loss: 0.0846\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0849 - val_loss: 0.0843\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0848 - val_loss: 0.0845\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0847 - val_loss: 0.0844\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0848 - val_loss: 0.0844\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0847 - val_loss: 0.0843\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0845 - val_loss: 0.0842\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0842 - val_loss: 0.0847\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0844 - val_loss: 0.0842\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0843 - val_loss: 0.0842\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0841 - val_loss: 0.0841\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0841 - val_loss: 0.0842\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0840 - val_loss: 0.0837\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0840 - val_loss: 0.0840\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0842 - val_loss: 0.0836\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0840 - val_loss: 0.0839\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0840 - val_loss: 0.0838\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0841 - val_loss: 0.0837\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0837 - val_loss: 0.0837\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0840 - val_loss: 0.0835\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0839 - val_loss: 0.0836\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0839 - val_loss: 0.0837\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0837 - val_loss: 0.0838\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0840 - val_loss: 0.0835\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0837 - val_loss: 0.0835\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0836 - val_loss: 0.0835\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0838 - val_loss: 0.0835\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0835 - val_loss: 0.0835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c782b8dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMkjtadsRX6"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf5YpXHdsmUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf51bbf7-4db4-4102-95e8-5762c902a1a2"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MAEbHep36Dr"
      },
      "source": [
        "#Generate noisy images\n",
        "#noise_factor = 0.5\n",
        "#x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "#x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "\n",
        "#x_train_noisy = np.clip(x_train_noisy, 0.0, 1.0)\n",
        "#x_test_noisy = np.clip(x_test_noisy, 0.0, 1.0)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e_KxyogsoFt"
      },
      "source": [
        "#tensorboard --logdir=/tmp/autoencoder"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76KRDch9sprK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432031e2-c5f8-4047-a245-4668cbcd9387"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 88s 160ms/step - loss: 0.3378 - val_loss: 0.1565\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 75s 160ms/step - loss: 0.1501 - val_loss: 0.1319\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 76s 162ms/step - loss: 0.1308 - val_loss: 0.1223\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 75s 161ms/step - loss: 0.1226 - val_loss: 0.1167\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 75s 159ms/step - loss: 0.1172 - val_loss: 0.1130\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 75s 159ms/step - loss: 0.1136 - val_loss: 0.1106\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 77s 165ms/step - loss: 0.1112 - val_loss: 0.1090\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 77s 163ms/step - loss: 0.1096 - val_loss: 0.1072\n",
            "Epoch 9/50\n",
            "361/469 [======================>.......] - ETA: 16s - loss: 0.1084"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIGFMSzfssj8"
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCC8bqLBsurb"
      },
      "source": [
        "encoder = keras.Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape((4, 4 * 8)).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_QcI1JvsyZt"
      },
      "source": [
        "#Image Denoising with Convolutional Autoencoder\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncdaYA2s85n"
      },
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dw1F-fKs-qz"
      },
      "source": [
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# At this point the representation is (7, 7, 32)\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2GLIePgtANS"
      },
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fxftAHstCkj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}